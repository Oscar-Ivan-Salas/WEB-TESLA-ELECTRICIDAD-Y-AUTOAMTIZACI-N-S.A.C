
const https = require('https');

const PI_API_URL = 'https://tesla-landing-self.vercel.app/api/chat';

const USERS = [
    { name: 'Usuario Prueba 1', phone: '+51900000001', service: 'AutomatizaciÃ³n' },
    { name: 'Usuario Prueba 2', phone: '+51900000002', service: 'Electricidad Industrial' },
    { name: 'Usuario Prueba 3', phone: '+51900000003', service: 'Pozos a Tierra' },
    { name: 'Usuario Prueba 4', phone: '+51900000004', service: 'Tableros ElÃ©ctricos' },
    { name: 'Usuario Prueba 5', phone: '+51900000005', service: 'DomÃ³tica' },
    { name: 'Usuario Prueba 6', phone: '+51900000006', service: 'CÃ¡maras de Seguridad' },
    { name: 'Usuario Prueba 7', phone: '+51900000007', service: 'Cableado Estructurado' },
    { name: 'Usuario Prueba 8', phone: '+51900000008', service: 'Certificaciones INDECI' },
    { name: 'Usuario Prueba 9', phone: '+51900000009', service: 'Montaje ElectromecÃ¡nico' },
    { name: 'Usuario Prueba 10', phone: '+51900000010', service: 'ConsultorÃ­a TÃ©cnica' },
];

function sendChatData(user, index) {
    return new Promise((resolve, reject) => {
        const sessionId = `stress-test-${Date.now()}-${index}`;

        // Simular sesiÃ³n finalizada
        const payload = JSON.stringify({
            sessionId: sessionId,
            message: "MaÃ±ana", // Finaliza con "Agendar Cita"
        });

        // Necesitamos 'pre-calentar' la sesiÃ³n o enviar el estado directamente?
        // El endpoint api/chat espera un objeto de sesiÃ³n existente para saber el estado.
        // Pero en la implementaciÃ³n actual, api/chat.js obtiene el estado de `sessions.get(sessionId)`.
        // Como es serverless (o local memory), si envÃ­o una sesiÃ³n NUEVA, empezarÃ¡ en START.

        // Â¡OJO! El servidor en Vercel NO mantiene memoria entre peticiones (Memory cache is ephemeral).
        // AsÃ­ que api/chat.js usando `const sessions = new Map()` NO FUNCIONARÃ bien en Vercel para mantener estado entre llamadas http distintas si la instancia se recicla.
        // PERO para la prueba de guardado, necesitamos llegar al estado END.

        // En Vercel, si queremos probar el guardado, tenemos que simular el paso final.
        // PERO si el servidor no tiene persistencia (Redis/DB), el flujo de chat multi-step fallarÃ¡ en deploy.
        // Ese es otro problema potencial de arquitectura.

        // SIN EMBARGO, para probar HOY el guardado, el flujo de chat debe funcionar en una sola instancia 'caliente' o necesitamos persistencia.
        // Si el usuario dice "no se guardan", es probable que porque el Map() se borra.

        // SOLUCIÃ“N RAPIDA PARA TEST: 
        // Vamos a modificar el script para enviar requests secuenciales rÃ¡pidos para UN usuario a ver si logra mantener la sesiÃ³n en la misma instancia de Vercel (a veces funciona si es seguido).
        // O MEJOR: Vamos a llamar directamente a `save-lead.js` si es posible? No, estÃ¡ protegido/interno en teorÃ­a. 
        // Pero `api/save-lead.js` exporta una funciÃ³n, y en Vercel se despliega como ruta `/api/save-lead`.
        // Â¡Podemos llamar a `/api/save-lead` directamente para probar la base de datos!

        // Vamos a probar AMBOS:
        // 1. Llamada directa a /api/save-lead (Simulando lo que harÃ­a el chat internamente).

        const dataToSave = JSON.stringify({
            session: {
                nombre: user.name,
                telefono: user.phone,
                tipo_proyecto: user.service,
                etapa: 'Stress Test',
                necesidad: 'Verificar DB',
                ubicacion: 'Remote Test',
                cita: 'Prueba AutomÃ¡tica'
            }
        });

        const options = {
            hostname: 'tesla-landing-self.vercel.app',
            path: '/api/save-lead',
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Content-Length': dataToSave.length,
            },
        };

        const req = https.request(options, (res) => {
            let responseBody = '';
            res.on('data', (chunk) => (responseBody += chunk));
            res.on('end', () => {
                const isSuccess = res.statusCode === 200 || res.statusCode === 201;
                // Check if body is error despite 200 status (Debug mode)
                if (responseBody.includes('"error"')) {
                    console.error(`âŒ User ${index + 1} (${user.name}): ERROR (Debug 200). Body: ${responseBody}`);
                } else if (isSuccess) {
                    console.log(`âœ… User ${index + 1} (${user.name}): GUARDADO. Status: ${res.statusCode}. Body: ${responseBody}`);
                    resolve();
                } else {
                    console.error(`âŒ User ${index + 1} (${user.name}): FALLÃ“. Status: ${res.statusCode}. Body: ${responseBody}`);
                    resolve(); // Resolvemos para seguir con los otros
                }
            });
        });

        req.on('error', (e) => {
            console.error(`âŒ User ${index + 1}: Error de red`, e);
            resolve();
        });

        req.write(dataToSave);
        req.end();
    });
}

async function runStressTest() {
    console.log('ğŸš€ Iniciando Stress Test (10 Usuarios) hacia PROD...');
    console.log('Target: https://tesla-landing-self.vercel.app/api/save-lead');

    // Ejecutar secuencialmente para ver logs claros (o paralelo si quieres stress real)
    // Vamos paralelo con pequeÃ±o delay para no ser baneados por rate limit si hubiera.

    for (let i = 0; i < USERS.length; i++) {
        await sendChatData(USERS[i], i);
        // PequeÃ±o delay de 500ms
        await new Promise(r => setTimeout(r, 500));
    }

    console.log('ğŸ Stress Test Finalizado.');
}

runStressTest();
